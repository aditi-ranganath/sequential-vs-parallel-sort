#include <stdlib.h>

#include <cuda.h>
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include "../Utils/constants_common.h"
#include "../Utils/data_types_common.h"
#include "../Utils/host.h"
#include "../Utils/cuda.h"
#include "constants.h"
#include "data_types.h"


/*
Allocates host memory.
*/
void allocHostMemory(
    data_t **input, data_t **outputParallel, data_t **outputSequential, data_t **outputCorrect,
    h_glob_seq_t **h_globalSeqHost, h_glob_seq_t **h_globalSeqHostBuffer, d_glob_seq_t **h_globalSeqDev,
    uint_t **h_globalSeqIndexes, loc_seq_t **h_localSeq, double ***timers, uint_t tableLen, uint_t testRepetitions
)
{
    // Maximum number of sequneces which can get generated by global quicksort. In global quicksort sequences
    // are generated untill total number of sequences is lower than: tableLen / THRESHOLD_PARTITION_SIZE_GLOBAL.
    uint_t maxNumSequences = 2 * ((tableLen - 1) / THRESHOLD_PARTITION_SIZE_GLOBAL + 1);
    // Max number of all thread blocks in GLOBAL quicksort.
    uint_t elemsPerThreadBlock = (THREADS_PER_SORT_GLOBAL * ELEMENTS_PER_THREAD_GLOBAL);
    uint_t maxNumThreadBlocks = maxNumSequences * ((THRESHOLD_PARTITION_SIZE_GLOBAL - 1) / elemsPerThreadBlock + 1);
    cudaError_t error;

    // Data input
    *input = (data_t*)malloc(tableLen * sizeof(**input));
    checkMallocError(*input);

    // Data output
    *outputParallel = (data_t*)malloc(tableLen * sizeof(**outputParallel));
    checkMallocError(*outputParallel);
    *outputSequential = (data_t*)malloc(tableLen * sizeof(**outputSequential));
    checkMallocError(*outputSequential);
    *outputCorrect = (data_t*)malloc(tableLen * sizeof(**outputCorrect));
    checkMallocError(*outputCorrect);

    // Global host sequences
    *h_globalSeqHost = (h_glob_seq_t*)malloc(maxNumSequences * sizeof(**h_globalSeqHost));
    *h_globalSeqHostBuffer = (h_glob_seq_t*)malloc(maxNumSequences * sizeof(**h_globalSeqHostBuffer));

    // These sequences are transfered between host and device and are therfore allocated in CUDA pinned memory
    error = cudaHostAlloc(h_globalSeqDev, maxNumSequences * sizeof(**h_globalSeqDev), cudaHostAllocDefault);
    checkCudaError(error);
    error = cudaHostAlloc(
        h_globalSeqIndexes, maxNumThreadBlocks * sizeof(**h_globalSeqIndexes), cudaHostAllocDefault
    );
    checkCudaError(error);
    error = cudaHostAlloc(h_localSeq, maxNumSequences * sizeof(**h_localSeq), cudaHostAllocDefault);
    checkCudaError(error);

    // Stopwatch times for PARALLEL, SEQUENTIAL and CORREECT
    double** timersTemp = new double*[NUM_STOPWATCHES];
    for (uint_t i = 0; i < NUM_STOPWATCHES; i++)
    {
        timersTemp[i] = new double[testRepetitions];
    }

    *timers = timersTemp;
}

/*
Frees host memory.
*/
void freeHostMemory(
    data_t *input, data_t *outputParallel, data_t *outputSequential, data_t *outputCorrect,
    h_glob_seq_t *h_globalSeqHost, h_glob_seq_t *h_globalSeqHostBuffer, d_glob_seq_t *h_globalSeqDev,
    uint_t *h_globalSeqIndexes, loc_seq_t *h_localSeq, double **timers
)
{
    cudaError_t error;

    free(input);
    free(outputParallel);
    free(outputSequential);
    free(outputCorrect);
    free(h_globalSeqHost);
    free(h_globalSeqHostBuffer);

    // These arrays are allocated in CUDA pinned memory
    error = cudaFree(h_globalSeqDev);
    checkCudaError(error);
    error = cudaFree(h_globalSeqIndexes);
    checkCudaError(error);
    error = cudaFree(h_localSeq);
    checkCudaError(error);

    for (uint_t i = 0; i < NUM_STOPWATCHES; ++i)
    {
        delete[] timers[i];
    }
    delete[] timers;
}

/*
Allocates device memory.
*/
void allocDeviceMemory(data_t **dataTable, uint_t tableLen)
{
    cudaError_t error;

    error = cudaMalloc(dataTable, tableLen * sizeof(**dataTable));
    checkCudaError(error);
}

/*
Frees device memory.
*/
void freeDeviceMemory(data_t *dataTable)
{
    cudaError_t error;

    error = cudaFree(dataTable);
    checkCudaError(error);
}
