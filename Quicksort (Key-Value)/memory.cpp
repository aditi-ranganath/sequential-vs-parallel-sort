#include <stdlib.h>

#include <cuda.h>
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include "../Utils/constants_common.h"
#include "../Utils/data_types_common.h"
#include "../Utils/host.h"
#include "../Utils/cuda.h"
#include "constants.h"
#include "data_types.h"


/*
Allocates host memory.
*/
void allocHostMemory(
    data_t **inputKeys, data_t **inputValues, data_t **outputParallelKeys, data_t **outputParallelValues,
    data_t **outputSequentialKeys, data_t **outputSequentialValues, data_t **outputCorrect,
    data_t **minMaxValues, h_glob_seq_t **globalSeqHost, h_glob_seq_t **globalSeqHostBuffer,
    d_glob_seq_t **globalSeqDev, uint_t **globalSeqIndexes, loc_seq_t **localSeq, double ***timers,
    uint_t tableLen, uint_t testRepetitions
)
{
    // Maximum number of sequneces which can get generated by global quicksort. In global quicksort sequences
    // are generated untill total number of sequences is lower than: tableLen / THRESHOLD_PARTITION_SIZE_GLOBAL.
    uint_t maxNumSequences = 2 * ((tableLen - 1) / THRESHOLD_PARTITION_SIZE_GLOBAL + 1);
    // Max number of all thread blocks in GLOBAL quicksort.
    uint_t elemsPerThreadBlock = THREADS_PER_SORT_GLOBAL * ELEMENTS_PER_THREAD_GLOBAL;
    uint_t maxNumThreadBlocks = maxNumSequences * ((THRESHOLD_PARTITION_SIZE_GLOBAL - 1) / elemsPerThreadBlock + 1);
    cudaError_t error;

    // Data input
    *inputKeys = (data_t*)malloc(tableLen * sizeof(**inputKeys));
    checkMallocError(*inputKeys);
    *inputValues = (data_t*)malloc(tableLen * sizeof(**inputValues));
    checkMallocError(*inputValues);

    // Data output
    *outputParallelKeys = (data_t*)malloc(tableLen * sizeof(**outputParallelKeys));
    checkMallocError(*outputParallelKeys);
    *outputParallelValues = (data_t*)malloc(tableLen * sizeof(**outputParallelValues));
    checkMallocError(*outputParallelValues);
    *outputSequentialKeys = (data_t*)malloc(tableLen * sizeof(**outputSequentialKeys));
    checkMallocError(*outputSequentialKeys);
    *outputSequentialValues = (data_t*)malloc(tableLen * sizeof(**outputSequentialValues));
    checkMallocError(*outputSequentialValues);
    *outputCorrect = (data_t*)malloc(tableLen * sizeof(**outputCorrect));
    checkMallocError(*outputCorrect);

    // Sequence metadata memory allocation
    *globalSeqHost = (h_glob_seq_t*)malloc(maxNumSequences * sizeof(**globalSeqHost));
    checkMallocError(*globalSeqHost);
    *globalSeqHostBuffer = (h_glob_seq_t*)malloc(maxNumSequences * sizeof(**globalSeqHostBuffer));
    checkMallocError(*globalSeqHostBuffer);

    // These sequences are transfered between host and device and are therfore allocated in CUDA pinned memory
    error = cudaHostAlloc(
        minMaxValues, 2 * THRESHOLD_REDUCTION * sizeof(**minMaxValues), cudaHostAllocDefault
    );
    checkCudaError(error);
    error = cudaHostAlloc(globalSeqDev, maxNumSequences * sizeof(**globalSeqDev), cudaHostAllocDefault);
    checkCudaError(error);
    error = cudaHostAlloc(
        globalSeqIndexes, maxNumThreadBlocks * sizeof(**globalSeqIndexes), cudaHostAllocDefault
    );
    checkCudaError(error);
    error = cudaHostAlloc(localSeq, maxNumSequences * sizeof(**localSeq), cudaHostAllocDefault);
    checkCudaError(error);

    // Stopwatch times for PARALLEL, SEQUENTIAL and CORREECT
    double** timersTemp = new double*[NUM_STOPWATCHES];
    for (uint_t i = 0; i < NUM_STOPWATCHES; i++)
    {
        timersTemp[i] = new double[testRepetitions];
    }

    *timers = timersTemp;
}

/*
Frees host memory.
*/
void freeHostMemory(
    data_t *inputKeys, data_t *inputValues, data_t *outputParallelKeys, data_t *outputParallelValues,
    data_t *outputSequentialKeys, data_t *outputSequentialValues, data_t *outputCorrect, data_t *minMaxValues,
    h_glob_seq_t *globalSeqHost, h_glob_seq_t *globalSeqHostBuffer, d_glob_seq_t *globalSeqDev,
    uint_t *globalSeqIndexes, loc_seq_t *localSeq, double **timers
)
{
    cudaError_t error;

    free(inputKeys);
    free(inputValues);
    free(outputParallelKeys);
    free(outputParallelValues);
    free(outputSequentialKeys);
    free(outputSequentialValues);
    free(outputCorrect);

    free(globalSeqHost);
    free(globalSeqHostBuffer);

    // These arrays are allocated in CUDA pinned memory
    error = cudaFreeHost(minMaxValues);
    checkCudaError(error);
    error = cudaFreeHost(globalSeqDev);
    checkCudaError(error);
    error = cudaFreeHost(globalSeqIndexes);
    checkCudaError(error);
    error = cudaFreeHost(localSeq);
    checkCudaError(error);

    for (uint_t i = 0; i < NUM_STOPWATCHES; ++i)
    {
        delete[] timers[i];
    }
    delete[] timers;
}

/*
Allocates device memory.
*/
void allocDeviceMemory(
    data_t **dataKeys, data_t **dataValues, data_t **bufferKeys, data_t **bufferValues, data_t **pivotValues,
    d_glob_seq_t **globalSeqDev, uint_t **globalSeqIndexes, loc_seq_t **localSeq, uint_t tableLen
)
{
    // Maximum number of sequneces which can get generated by global quicksort. In global quicksort sequences
    // are generated untill total number of sequences is lower than: tableLen / THRESHOLD_PARTITION_SIZE_GLOBAL.
    uint_t maxNumSequences = 2 * ((tableLen - 1) / THRESHOLD_PARTITION_SIZE_GLOBAL + 1);
    // Max number of all thread blocks in GLOBAL quicksort.
    uint_t elemsPerThreadBlock = THREADS_PER_SORT_GLOBAL * ELEMENTS_PER_THREAD_GLOBAL;
    uint_t maxNumThreadBlocks = maxNumSequences * ((THRESHOLD_PARTITION_SIZE_GLOBAL - 1) / elemsPerThreadBlock + 1);
    cudaError_t error;

    error = cudaMalloc(dataKeys, tableLen * sizeof(**dataKeys));
    checkCudaError(error);
    error = cudaMalloc(dataValues, tableLen * sizeof(**dataValues));
    checkCudaError(error);
    error = cudaMalloc(bufferKeys, tableLen * sizeof(**bufferKeys));
    checkCudaError(error);
    error = cudaMalloc(bufferValues, tableLen * sizeof(**bufferValues));
    checkCudaError(error);
    error = cudaMalloc(pivotValues, tableLen * sizeof(**pivotValues));
    checkCudaError(error);

    // Sequence metadata memory allocation
    error = cudaMalloc(globalSeqDev, maxNumSequences * sizeof(**globalSeqDev));
    checkCudaError(error);
    error = cudaMalloc(globalSeqIndexes, maxNumThreadBlocks * sizeof(**globalSeqIndexes));
    checkCudaError(error);
    error = cudaMalloc(localSeq, maxNumSequences * sizeof(**localSeq));
    checkCudaError(error);
}

/*
Frees device memory.
*/
void freeDeviceMemory(
    data_t *dataKeys, data_t *dataValues, data_t *bufferKeys, data_t *bufferValues, data_t *pivotValues,
    d_glob_seq_t *globalSeqDev, uint_t *globalSeqIndexes, loc_seq_t *localSeq
)
{
    cudaError_t error;

    error = cudaFree(dataKeys);
    checkCudaError(error);
    error = cudaFree(dataValues);
    checkCudaError(error);
    error = cudaFree(bufferKeys);
    checkCudaError(error);
    error = cudaFree(bufferValues);
    checkCudaError(error);
    error = cudaFree(pivotValues);
    checkCudaError(error);

    error = cudaFree(globalSeqDev);
    checkCudaError(error);
    error = cudaFree(globalSeqIndexes);
    checkCudaError(error);
    error = cudaFree(localSeq);
    checkCudaError(error);
}
