#include <cuda.h>
#include "cuda_runtime.h"
#include "device_launch_parameters.h"

#include "constants.h"
#include "sort.h"


void QuicksortParallel::memoryAllocate(data_t *h_keys, data_t *h_values, uint_t arrayLength)
{
    SortParallel::memoryAllocate(h_keys, h_values, arrayLength);

    // Min/Max calculations needed, because mamory is allocated both for key only and for key-value sort
    uint_t minPartitionSizeGlobal = min(THRESHOLD_PARTITION_SIZE_GLOBAL_KO, THRESHOLD_PARTITION_SIZE_GLOBAL_KV);
    uint_t maxPartitionSizeGlobal = max(THRESHOLD_PARTITION_SIZE_GLOBAL_KO, THRESHOLD_PARTITION_SIZE_GLOBAL_KV);
    uint_t maxThreasholdReduction = max(THRESHOLD_REDUCTION_KO, THRESHOLD_REDUCTION_KV);
    uint_t minElemsPerThreadBlock = min(
        THREADS_PER_SORT_GLOBAL_KO * ELEMENTS_PER_THREAD_GLOBAL_KO,
        THREADS_PER_SORT_GLOBAL_KV * ELEMENTS_PER_THREAD_GLOBAL_KV
    );

    // Maximum number of sequneces which can get generated by global quicksort. In global quicksort sequences
    // are generated untill total number of sequences is lower than: tableLen / THRESHOLD_PARTITION_SIZE_GLOBAL.
    uint_t maxNumSequences = 2 * ((arrayLength - 1) / minPartitionSizeGlobal + 1);
    // Max number of all thread blocks in GLOBAL quicksort.
    uint_t maxNumThreadBlocks = maxNumSequences * ((maxPartitionSizeGlobal - 1) / minElemsPerThreadBlock + 1);
    cudaError_t error;

    /* HOST MEMORY */

    // Sequence metadata memory allocation
    _h_globalSeqHost = (h_glob_seq_t*)malloc(maxNumSequences * sizeof(*_h_globalSeqHost));
    checkMallocError(_h_globalSeqHost);
    _h_globalSeqHostBuffer = (h_glob_seq_t*)malloc(maxNumSequences * sizeof(*_h_globalSeqHostBuffer));
    checkMallocError(_h_globalSeqHostBuffer);

    // These sequences are transfered between host and device and are therfore allocated in CUDA pinned memory
    error = cudaHostAlloc(
        (void **)&_h_minMaxValues, 2 * maxThreasholdReduction * sizeof(*_h_minMaxValues), cudaHostAllocDefault
    );
    checkCudaError(error);
    error = cudaHostAlloc(
        (void **)&_h_globalSeqDev, maxNumSequences * sizeof(*_h_globalSeqDev), cudaHostAllocDefault
    );
    checkCudaError(error);
    error = cudaHostAlloc(
        (void **)&_h_globalSeqIndexes, maxNumThreadBlocks * sizeof(*_h_globalSeqIndexes), cudaHostAllocDefault
    );
    checkCudaError(error);
    error = cudaHostAlloc(
        (void **)&_h_localSeq, maxNumSequences * sizeof(*_h_localSeq), cudaHostAllocDefault
    );
    checkCudaError(error);

    /* DEVICE_MEMORY */

    error = cudaMalloc((void **)&_d_keysBuffer, arrayLength * sizeof(*_d_keysBuffer));
    checkCudaError(error);
    error = cudaMalloc((void **)&_d_valuesBuffer, arrayLength * sizeof(*_d_valuesBuffer));
    checkCudaError(error);
    error = cudaMalloc((void **)&_d_valuesPivot, arrayLength * sizeof(*_d_valuesPivot));
    checkCudaError(error);

    // Sequence metadata memory allocation
    error = cudaMalloc((void **)&_d_globalSeqDev, maxNumSequences * sizeof(*_d_globalSeqDev));
    checkCudaError(error);
    error = cudaMalloc((void **)&_d_globalSeqIndexes, maxNumThreadBlocks * sizeof(*_d_globalSeqIndexes));
    checkCudaError(error);
    error = cudaMalloc((void **)&_d_localSeq, maxNumSequences * sizeof(*_d_localSeq));
    checkCudaError(error);

}

void QuicksortParallel::memoryDestroy()
{
    SortParallel::memoryDestroy();

    if (_arrayLength == 0)
    {
        return;
    }

    cudaError_t error;

    /* HOST MEMORY */

    free(_h_globalSeqHost);
    free(_h_globalSeqHostBuffer);

    // These arrays are allocated in CUDA pinned memory
    error = cudaFreeHost(_h_minMaxValues);
    checkCudaError(error);
    error = cudaFreeHost(_h_globalSeqDev);
    checkCudaError(error);
    error = cudaFreeHost(_h_globalSeqIndexes);
    checkCudaError(error);
    error = cudaFreeHost(_h_localSeq);
    checkCudaError(error);

    /* DEVICE MEMORY */

    error = cudaFree(_d_keysBuffer);
    checkCudaError(error);
    error = cudaFree(_d_valuesBuffer);
    checkCudaError(error);
    error = cudaFree(_d_valuesPivot);
    checkCudaError(error);

    error = cudaFree(_d_globalSeqDev);
    checkCudaError(error);
    error = cudaFree(_d_globalSeqIndexes);
    checkCudaError(error);
    error = cudaFree(_d_localSeq);
    checkCudaError(error);
}

/*
Copies data from device to host. If sorting keys only, than "h_values" contains NULL.
Result is contained in buffer arrays, not in primary array.
*/
void QuicksortParallel::memoryCopyAfterSort(data_t *h_keys, data_t *h_values, uint_t arrayLength)
{
    cudaError_t error;

    // Copies keys
    error = cudaMemcpy(
        h_keys, (void *)_d_keysBuffer, _arrayLength * sizeof(*_h_keys), cudaMemcpyDeviceToHost
    );
    checkCudaError(error);

    if (h_values == NULL)
    {
        return;
    }

    // Copies values
    error = cudaMemcpy(
        h_values, (void *)_d_valuesBuffer, arrayLength * sizeof(*h_values), cudaMemcpyDeviceToHost
    );
    checkCudaError(error);
}
